{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary investigation - Feature engineering and Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still working. For data analysis and visualisation, please check the \"detailed_analysis_visual_on_income\" notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "# sklearn.set_config(print_changed_only=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/adult.csv\", index_col=0)\n",
    "df['income'] = df['income'].str.replace(\" \", \"\")\n",
    "df.head()\n",
    "\n",
    "df_process = df.copy()\n",
    "# Think for this data, because the target column (income) is a binary value, using x-y plot is difficult to \n",
    "# see the relationship between x and y. I think it is better to use histogram, with y as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def label_encode(df, X_col, label_encode_col):\n",
    "# y_encode_col = 'income'\n",
    "\n",
    "    LEncoder = LabelEncoder()\n",
    "    OHEncoder = OneHotEncoder()\n",
    "\n",
    "    X_label_enc = df[X_col]\n",
    "\n",
    "    for col in label_encode_col:\n",
    "        # The column names have a space in front. Clear it\n",
    "    #     cleaned_col = col.replace(' ', '')\n",
    "    #     print(cleaned_col)\n",
    "\n",
    "        ## TODO Fixed the empty space in front of the column name\n",
    "        temp_dummy = pd.get_dummies(X_label_enc[col],prefix=col,prefix_sep='-')\n",
    "        cleaned_val = [c.replace(' ','') for c in temp_dummy.columns]\n",
    "        cleaned_cols = {k:v for (k,v) in zip(temp_dummy.columns, cleaned_val)}\n",
    "    #     print(cleaned_cols)\n",
    "        temp_dummy.rename(columns=cleaned_cols, inplace=True)\n",
    "    #     print('temp_dummy.columns:', temp_dummy.head(2))\n",
    "        X_label_enc.drop(columns=col, inplace=True)\n",
    "        X_label_enc = X_label_enc.merge(temp_dummy, left_index=True, right_index=True)\n",
    "    #     print(X_label_enc.columns)\n",
    "\n",
    "    #     print(X)\n",
    "    # Use for loop to fit and trasnform each column that needs to be encoded\n",
    "    #     X_label_enc[col] = LEncoder.fit_transform(X_label_enc[col])\n",
    "    #     X_label_enc[col] = OHEncoder.fit_transform(X_label_enc[col].reshape(-1,1))\n",
    "\n",
    "\n",
    "    # print(pd.get_dummies(X_label_enc['workclass']))\n",
    "\n",
    "    # LEncoder.fit_transform(df[columns[0]])\n",
    "    y_encode = LEncoder.fit_transform(y)\n",
    "\n",
    "    print(X_label_enc.columns)\n",
    "    \n",
    "    return X_label_enc, y_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not including education because it has strong correlation with education-num\n",
    "label_encode_col = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender']\n",
    "\n",
    "X_label_enc, y_encode = label_encode(df, X_col, label_encode_col)\n",
    "\n",
    "print(y_encode)\n",
    "\n",
    "X_label_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native country to be engineered further.\n",
    "# Maybe use some factors to categorise countries such as: \n",
    "# 1. GPP (Gross average per person)\n",
    "# https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita\n",
    "# 2. Cultural similarities (maybe simply English-speaking and non-English speaking?)\n",
    "# https://www.economist.com/graphic-detail/2019/12/04/where-are-the-worlds-best-english-speakers\n",
    "# https://ceoworld.biz/2019/11/05/revealed-the-worlds-best-non-native-english-speaking-countries-2019/\n",
    "# 3. Geographical location (continent)\n",
    "\n",
    "\n",
    "# Easy version\n",
    "US_check = ['united-states', 'outlying-us(guam-usvi-etc)']\n",
    "\n",
    "# Need to do strip because there is weird space in entries\n",
    "temp_native_country = df_process['native-country'].apply(lambda x: 1 if x.lower().strip() in US_check else 0)\n",
    "\n",
    "native_country_dummy = pd.get_dummies(temp_native_country, prefix='native-country: US or not', prefix_sep='-')\n",
    "\n",
    "\n",
    "df_process = df_process.merge(native_country_dummy, left_index=True, right_index=True)\n",
    "\n",
    "# print(df_process['native-country'][0].lower().strip())\n",
    "\n",
    "# print(df_process['native-country'].value_counts())\n",
    "# print(temp_n_country)\n",
    "# print(native_country_dummy)\n",
    "df_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complicated method\n",
    "# Get the GDP and English fluency information\n",
    "dict_country_GDP = {}\n",
    "dict_country_Eng_fluency = {}\n",
    "\n",
    "temp_country_GDP # bin this using qcut\n",
    "temp_Eng_fluency # bin this using qcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that perform vertical quartile quantification and then horizontal binning\n",
    "Since several columns require the same procedure (age, capital-gain and capital-loss), will write functions here\n",
    "for calling <br>\n",
    "For capital-gain and capital-loss, because there are too many different horizontal values (different amount of capital-gain/capital-loss, thus, would just use a horizontal qcut and omit the vertical one. <br><br>\n",
    "Because most people have 0 capital-gain, most quartiles are concentrated close to 0 too.\n",
    "By setting duplicate drop, don't get to see a lot of different bins even though quartile cut is big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital-gain and capital-loss analysis\n",
    "There are too many different values for capital-gain and capital-loss (and quite a few outliers).\n",
    "So similar to age feature engineering, I will use a vertical quartile quantification method to limit the horizontal ranges.\n",
    "The amount of money is again a continuous value, so might have to consider to similar things as age featuring\n",
    "where I do the horizontal binning based on levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_num_col(df, col, q_num, drop_zero=False):\n",
    "    # binning numerical columns with qcut. col should just be one column string. q_num is the number of bins to be made\n",
    "    # if drop_zero=True, set zero as one of the bin then drop it, then perform qcut with the rest\n",
    "    # print(df_process['capital-gain'])\n",
    "    # df_process['capital-gain'].value_counts() # Most people have 0 capital-gain (perhaps no investment?)\n",
    "    binned = []\n",
    "#     temp_df = df.copy()\n",
    "    \n",
    "    if drop_zero == True:\n",
    "        binned.extend([-0.01, 0.01])\n",
    "        temp_df = df[(df[col] < -0.01) | (df[col] > 0.01)][col]\n",
    "        print(temp_df)\n",
    "    else:\n",
    "        temp_df = df[col]\n",
    "    \n",
    "    if col in df.columns:\n",
    "        ser, temp_binned = pd.qcut(temp_df, q=q_num, duplicates=\"drop\", retbins=True)\n",
    "        # With retbins=True, pd.qcut returns a tuple whose second element is the bins\n",
    "        # The first return element is a series while the second one is the break point\n",
    "        binned.extend(temp_binned)\n",
    "        print(binned)\n",
    "\n",
    "        # bin_cap_gain -= 0.01\n",
    "        # Need to do this because the cut is excluding the left hand side boundary value, which means 0 would not\n",
    "        # be include in (0 x]\n",
    "\n",
    "        binned_col = pd.cut(df[col], bins=binned, include_lowest=True)\n",
    "\n",
    "        binned_dummy = pd.get_dummies(binned_col,prefix= col + '_binned',prefix_sep='-')\n",
    "#         df.drop(columns=[col], inplace=True)  \n",
    "        df = df.merge(binned_dummy, left_index=True, right_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2174\n",
      "8        14084\n",
      "9         5178\n",
      "59        5013\n",
      "60        2407\n",
      "84       14344\n",
      "101      15024\n",
      "105       7688\n",
      "106      34095\n",
      "113       4064\n",
      "132       4386\n",
      "197      14084\n",
      "198       7298\n",
      "206       7298\n",
      "208      15024\n",
      "227       1409\n",
      "230       3674\n",
      "263       4064\n",
      "271       1055\n",
      "272       2407\n",
      "276       7298\n",
      "279       7298\n",
      "281       5178\n",
      "285      15024\n",
      "297       3464\n",
      "300       7688\n",
      "303       4386\n",
      "311       7298\n",
      "329       2050\n",
      "341       7298\n",
      "         ...  \n",
      "32098     7298\n",
      "32123    13550\n",
      "32139    15024\n",
      "32155     1055\n",
      "32156     7298\n",
      "32164    10520\n",
      "32169     4101\n",
      "32179     5178\n",
      "32198    20051\n",
      "32203    15024\n",
      "32228     7688\n",
      "32238    99999\n",
      "32249     7688\n",
      "32308     3103\n",
      "32341    15831\n",
      "32354     6849\n",
      "32365    15024\n",
      "32367     2653\n",
      "32370    27828\n",
      "32388     1471\n",
      "32399     7298\n",
      "32434     7443\n",
      "32462     7298\n",
      "32466    15024\n",
      "32473     1506\n",
      "32515     3471\n",
      "32518    99999\n",
      "32538    15020\n",
      "32548     1086\n",
      "32560    15024\n",
      "Name: capital-gain, Length: 2712, dtype: int64\n",
      "[-0.01, 0.01, 114.0, 3103.0, 5013.0, 7688.0, 15024.0, 99999.0]\n",
      "23       2042\n",
      "32       1408\n",
      "52       1902\n",
      "93       1573\n",
      "96       1902\n",
      "112      1887\n",
      "126      1719\n",
      "131      1762\n",
      "143      1564\n",
      "148      2179\n",
      "157      1816\n",
      "170      1980\n",
      "172      1977\n",
      "200      1876\n",
      "203      1340\n",
      "222      2206\n",
      "244      1741\n",
      "248      1977\n",
      "321      1485\n",
      "327      1887\n",
      "363      1564\n",
      "381      2339\n",
      "387      2415\n",
      "404      2179\n",
      "405      1977\n",
      "408      1887\n",
      "426      1408\n",
      "434      1980\n",
      "468      1977\n",
      "510      1380\n",
      "         ... \n",
      "32013    2051\n",
      "32020    1762\n",
      "32035    1672\n",
      "32092    1887\n",
      "32131    1977\n",
      "32135    2258\n",
      "32138    2444\n",
      "32147    1408\n",
      "32159    1602\n",
      "32216    1902\n",
      "32218    1672\n",
      "32221    1902\n",
      "32230    2415\n",
      "32250    1977\n",
      "32254    1485\n",
      "32264    2042\n",
      "32266    1887\n",
      "32267    1902\n",
      "32270    2042\n",
      "32301    1411\n",
      "32307    1977\n",
      "32311    2559\n",
      "32393    1741\n",
      "32400    1887\n",
      "32416    1902\n",
      "32441    1887\n",
      "32443    1602\n",
      "32445    1669\n",
      "32458    1977\n",
      "32500     880\n",
      "Name: capital-loss, Length: 1519, dtype: int64\n",
      "[-0.01, 0.01, 155.0, 1617.0, 1876.0, 1902.0, 2001.0, 4356.0]\n",
      "[1.0, 9.0, 10.0, 13.0, 16.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>...</th>\n",
       "      <th>capital-loss_binned-(0.01, 155.0]</th>\n",
       "      <th>capital-loss_binned-(155.0, 1617.0]</th>\n",
       "      <th>capital-loss_binned-(1617.0, 1876.0]</th>\n",
       "      <th>capital-loss_binned-(1876.0, 1902.0]</th>\n",
       "      <th>capital-loss_binned-(1902.0, 2001.0]</th>\n",
       "      <th>capital-loss_binned-(2001.0, 4356.0]</th>\n",
       "      <th>education-num_binned-(0.999, 9.0]</th>\n",
       "      <th>education-num_binned-(9.0, 10.0]</th>\n",
       "      <th>education-num_binned-(10.0, 13.0]</th>\n",
       "      <th>education-num_binned-(13.0, 16.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "                 ...                  capital-loss_binned-(0.01, 155.0]  \\\n",
       "0                ...                                                  0   \n",
       "1                ...                                                  0   \n",
       "2                ...                                                  0   \n",
       "3                ...                                                  0   \n",
       "4                ...                                                  0   \n",
       "\n",
       "   capital-loss_binned-(155.0, 1617.0] capital-loss_binned-(1617.0, 1876.0]  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "  capital-loss_binned-(1876.0, 1902.0]  capital-loss_binned-(1902.0, 2001.0]  \\\n",
       "0                                    0                                     0   \n",
       "1                                    0                                     0   \n",
       "2                                    0                                     0   \n",
       "3                                    0                                     0   \n",
       "4                                    0                                     0   \n",
       "\n",
       "   capital-loss_binned-(2001.0, 4356.0]  education-num_binned-(0.999, 9.0]  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     0                                  1   \n",
       "3                                     0                                  1   \n",
       "4                                     0                                  0   \n",
       "\n",
       "   education-num_binned-(9.0, 10.0]  education-num_binned-(10.0, 13.0]  \\\n",
       "0                                 0                                  1   \n",
       "1                                 0                                  1   \n",
       "2                                 0                                  0   \n",
       "3                                 0                                  0   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   education-num_binned-(13.0, 16.0]  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process = bin_num_col(df_process, 'capital-gain', 5, drop_zero=True)\n",
    "df_process = bin_num_col(df_process, 'capital-loss', 5, drop_zero=True)\n",
    "df_process = bin_num_col(df_process, 'education-num', 5)\n",
    "\n",
    "df_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly perform the same with capital-loss\n",
    "df_process['capital-loss'].describe()\n",
    "\n",
    "bin_cap_loss = pd.qcut(df_process['capital-loss'], q=50, duplicates=\"drop\")\n",
    "\n",
    "print(bin_cap_loss.value_counts())\n",
    "print(df_process[df_process['capital-loss'] < 1590]['capital-loss'].value_counts())\n",
    "\n",
    "# df_process['capital-gain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age feature engineering\n",
    "The ratio between people earning more than 50K and less than 50K changes with the age group.\n",
    "With that, binning would be more effective if we can set the boundary at which the ratios change a lot.\n",
    "\n",
    "1. In this example, all bins have more people earning less than 50K than people earning more than 50K. So the ratio would just be (Number of people earning less than 50K)/(Number of people earning more than 50K).\n",
    "2. Some of the ratios can be huge (at young age) compared to low ratios. To reduce the effect of big ratio and increase the effect of smaller ratio change, log transfomration would be applied\n",
    "3. Final step is to apply \"Bayesian blocks\", which is an adaptive method to find the optimal binning strategy\n",
    "\n",
    "For a set of histogram bins or blocks, each of an arbirary size, one can use a Bayesain likelihood framework to compute a fitness function which only depeds on two numbers: the width of each block, and the number of points in each block. The edges betwen these blocks (the change-points) can be varied, and the overall block configuration with the maximum fitness is quantitatively the est binning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_blocks(t):\n",
    "    \"\"\"Bayesian Blocks Implementation\n",
    "\n",
    "    By Jake Vanderplas.  License: BSD\n",
    "    Based on algorithm outlined in http://adsabs.harvard.edu/abs/2012arXiv1207.5578S\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, length N\n",
    "        data to be histogrammed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bins : ndarray\n",
    "        array containing the (N+1) bin edges\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is an incomplete implementation: it may fail for some\n",
    "    datasets.  Alternate fitness functions and prior forms can\n",
    "    be found in the paper listed above.\n",
    "    \"\"\"\n",
    "    # copy and sort the array\n",
    "    t = np.sort(t)\n",
    "    N = t.size\n",
    "\n",
    "    # create length-(N + 1) array of cell edges\n",
    "    edges = np.concatenate([t[:1],\n",
    "                            0.5 * (t[1:] + t[:-1]),\n",
    "                            t[-1:]])\n",
    "    block_length = t[-1] - edges\n",
    "\n",
    "    # arrays needed for the iteration\n",
    "    nn_vec = np.ones(N)\n",
    "    best = np.zeros(N, dtype=float)\n",
    "    last = np.zeros(N, dtype=int)\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # Start with first data cell; add one cell at each iteration\n",
    "    #-----------------------------------------------------------------\n",
    "    for K in range(N):\n",
    "        # Compute the width and count of the final bin for all possible\n",
    "        # locations of the K^th changepoint\n",
    "        width = block_length[:K + 1] - block_length[K + 1]\n",
    "        count_vec = np.cumsum(nn_vec[:K + 1][::-1])[::-1]\n",
    "\n",
    "        # evaluate fitness function for these possibilities\n",
    "        fit_vec = count_vec * (np.log(count_vec) - np.log(width))\n",
    "        fit_vec -= 4  # 4 comes from the prior on the number of changepoints\n",
    "        print(fit_vec)\n",
    "        fit_vec[1:] += best[:K]\n",
    "\n",
    "        # find the max of the fitness: this is the K^th changepoint\n",
    "        i_max = np.argmax(fit_vec)\n",
    "        last[K] = i_max\n",
    "        best[K] = fit_vec[i_max]\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # Recover changepoints by iteratively peeling off the last block\n",
    "    #-----------------------------------------------------------------\n",
    "    change_points =  np.zeros(N, dtype=int)\n",
    "    i_cp = N\n",
    "    ind = N\n",
    "    while True:\n",
    "        i_cp -= 1\n",
    "        change_points[i_cp] = ind\n",
    "        if ind == 0:\n",
    "            break\n",
    "        ind = last[ind - 1]\n",
    "    change_points = change_points[i_cp:]\n",
    "\n",
    "    return edges[change_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_age_ratio_diff = log_age_ratio.to_frame().T.diff(axis=1)\n",
    "\n",
    "log_age_ratio.plot.bar()\n",
    "log_age_ratio_diff.T.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hori_bound(s):\n",
    "# This function takes in either series or a list of time-series like values that have been quantified with vertical qcut\n",
    "# To reduce the number of discrete values in binning, a simple boundary values would be returned for horizontal qcut\n",
    "# Within each boundary, the vertical (y-axis) values would be the same\n",
    "# At the moment there is no smoothing method, bumpy vertical values within a long stretch of vertical values\n",
    "# would have its own boundary\n",
    "\n",
    "# The algorithm is simple too, whenever vertical value is the same, no boundary is set and move on to the next sample\n",
    "# If the vertical value is different, then a boundary is set and the new vertical value is set\n",
    "    bin_boundary = []\n",
    "    prev_yval = None\n",
    "    labels = []\n",
    "    \n",
    "#     curr_\n",
    "    \n",
    "    for row in s.iteritems():\n",
    "        if not prev_yval or not row[1] == prev_yval:\n",
    "            prev_yval = row[1]\n",
    "#             print(row.index)\n",
    "            bin_boundary.append(row[0])   \n",
    "    \n",
    "\n",
    "    return bin_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_qcut_val = pd.qcut(log_age_ratio, 5)\n",
    "print(vert_qcut_val.unique()[0].left)\n",
    "\n",
    "print(vert_qcut_val.unique())\n",
    "\n",
    "interval=[]\n",
    "mid_val = []\n",
    "labels = []\n",
    "\n",
    "for v in vert_qcut_val.unique():\n",
    "    interval.append(v.left)\n",
    "    interval.append(v.right)\n",
    "    mid_val.append((v.left + v.right)/2)\n",
    "    \n",
    "    \n",
    "vert_qcut_list = sorted(set(interval))\n",
    "mid_val_list = sorted(set(mid_val))\n",
    "\n",
    "print(mid_val_list)\n",
    "print(labels)\n",
    "\n",
    "bin_log_age_ratio = pd.cut(x=log_age_ratio, bins=vert_qcut_list, labels=mid_val_list)\n",
    "\n",
    "# bin_log_age_ratio.to_frame().T.plot.bar()\n",
    "# test.to_frame().plot.bar()\n",
    "bin_boundary = get_hori_bound(bin_log_age_ratio)\n",
    "\n",
    "df_process['age-binned'] = pd.cut(df_process['age'], bins=bin_boundary)\n",
    "\n",
    "age_binned_dummy = pd.get_dummies(df_process['age-binned'],prefix='age-binned',prefix_sep='-')\n",
    "\n",
    "# df_process.drop(columns=col, inplace=True)\n",
    "df_process = df_process.merge(age_binned_dummy, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "print(bin_boundary)\n",
    "# df_process[['age','age_binned']].head()\n",
    "df_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform automatic binning on continuous values\n",
    "\n",
    "# test = pd.qcut(df['age'].values, 5, \\\n",
    "#                labels=['young', 'prime-time', 'middle-age','retiring', 'senior']) # Categorical if given is array\n",
    "\n",
    "test = pd.qcut(df['age'], 10) # Categorical if given is array\n",
    "\n",
    "print(test.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
