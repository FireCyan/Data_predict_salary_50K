{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary investigation - Feature engineering and Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still working. For data analysis and visualisation, please check the \"detailed_analysis_visual_on_income\" notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "# sklearn.set_config(print_changed_only=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "education         object\n",
      "marital-status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "gender            object\n",
      "capital-gain       int64\n",
      "capital-loss       int64\n",
      "hours-per-week     int64\n",
      "native-country    object\n",
      "income            object\n",
      "dtype: object\n",
      "['age' 'capital-gain' 'capital-loss' 'hours-per-week']\n",
      "['workclass' 'education' 'marital-status' 'occupation' 'relationship'\n",
      " 'race' 'gender' 'native-country' 'income']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education       marital-status  \\\n",
       "0   39          State-gov   Bachelors        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors   Married-civ-spouse   \n",
       "2   38            Private     HS-grad             Divorced   \n",
       "3   53            Private        11th   Married-civ-spouse   \n",
       "4   28            Private   Bachelors   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country income  \n",
       "0             0              40   United-States  <=50K  \n",
       "1             0              13   United-States  <=50K  \n",
       "2             0              40   United-States  <=50K  \n",
       "3             0              40   United-States  <=50K  \n",
       "4             0              40            Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/adult.csv\", index_col=0)\n",
    "df['income'] = df['income'].str.replace(\" \", \"\")\n",
    "\n",
    "# remove the column education-num because it is similar to education\n",
    "df = df.drop(columns=['education-num'])\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "kinds = np.array([dt.kind for dt in df.dtypes])\n",
    "# print(kinds)\n",
    "\n",
    "all_col = df.columns.values\n",
    "is_num = kinds != 'O'\n",
    "# print(is_num)\n",
    "num_col = all_col[is_num]\n",
    "print(num_col)\n",
    "\n",
    "cat_col = all_col[~is_num]\n",
    "print(cat_col)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Think for this data, because the target column (income) is a binary value, using x-y plot is difficult to \n",
    "# see the relationship between x and y. I think it is better to use histogram, with y as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features:\n",
    "* Workclass (categorical)\n",
    "* education (categorical)\n",
    "* marital-status (categorical)\n",
    "* occupation (categorical)\n",
    "* relationship (categorical)\n",
    "* race (categorical)\n",
    "* gender (categorical)\n",
    "\n",
    "* native-country (categorical with engineering)\n",
    "\n",
    "\n",
    "* age (numerical values)\n",
    "* education-num (numerical values) (deleted)\n",
    "* hours-per-week (numerical values)\n",
    "* capital-gain (numerical values)\n",
    "* capital-loss (numerical values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def label_encode(df, X_col, label_encode_col, Y_col=''):\n",
    "# y_encode_col = 'income'\n",
    "# X_col is the column names of the features that I am going to use.\n",
    "# label_encode_col is a list that contains the columns that one wants to encode \n",
    "\n",
    "    LEncoder = LabelEncoder()\n",
    "    OHEncoder = OneHotEncoder()\n",
    "\n",
    "    X_label_enc = df[X_col]\n",
    "    \n",
    "    if Y_col:\n",
    "        y = df[Y_col]\n",
    "    else:\n",
    "        y = df[df.columns[-1]]\n",
    "\n",
    "    for col in label_encode_col:\n",
    "        # The column names have a space in front. Clear it\n",
    "    #     cleaned_col = col.replace(' ', '')\n",
    "    #     print(cleaned_col)\n",
    "\n",
    "        ## TODO Fixed the empty space in front of the column name\n",
    "        temp_dummy = pd.get_dummies(X_label_enc[col],prefix=col,prefix_sep='-')\n",
    "        cleaned_val = [c.replace(' ','') for c in temp_dummy.columns]\n",
    "        cleaned_cols = {k:v for (k,v) in zip(temp_dummy.columns, cleaned_val)}\n",
    "    #     print(cleaned_cols)\n",
    "        temp_dummy.rename(columns=cleaned_cols, inplace=True)\n",
    "    #     print('temp_dummy.columns:', temp_dummy.head(2))\n",
    "        X_label_enc.drop(columns=col, inplace=True)\n",
    "        X_label_enc = X_label_enc.merge(temp_dummy, left_index=True, right_index=True)\n",
    "    #     print(X_label_enc.columns)\n",
    "\n",
    "    #     print(X)\n",
    "    # Use for loop to fit and trasnform each column that needs to be encoded\n",
    "    #     X_label_enc[col] = LEncoder.fit_transform(X_label_enc[col])\n",
    "    #     X_label_enc[col] = OHEncoder.fit_transform(X_label_enc[col].reshape(-1,1))\n",
    "\n",
    "\n",
    "    # print(pd.get_dummies(X_label_enc['workclass']))\n",
    "\n",
    "    # LEncoder.fit_transform(df[columns[0]])\n",
    "    y_encode = LEncoder.fit_transform(y)\n",
    "    \n",
    "    return X_label_enc, y_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week', 'native-country'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass-?</th>\n",
       "      <th>workclass-Federal-gov</th>\n",
       "      <th>workclass-Local-gov</th>\n",
       "      <th>workclass-Never-worked</th>\n",
       "      <th>workclass-Private</th>\n",
       "      <th>workclass-Self-emp-inc</th>\n",
       "      <th>workclass-Self-emp-not-inc</th>\n",
       "      <th>workclass-State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country-Portugal</th>\n",
       "      <th>native-country-Puerto-Rico</th>\n",
       "      <th>native-country-Scotland</th>\n",
       "      <th>native-country-South</th>\n",
       "      <th>native-country-Taiwan</th>\n",
       "      <th>native-country-Thailand</th>\n",
       "      <th>native-country-Trinadad&amp;Tobago</th>\n",
       "      <th>native-country-United-States</th>\n",
       "      <th>native-country-Vietnam</th>\n",
       "      <th>native-country-Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  hours-per-week  workclass-?  workclass-Federal-gov  \\\n",
       "0   39              40            0                      0   \n",
       "1   50              13            0                      0   \n",
       "2   38              40            0                      0   \n",
       "3   53              40            0                      0   \n",
       "4   28              40            0                      0   \n",
       "\n",
       "   workclass-Local-gov  workclass-Never-worked  workclass-Private  \\\n",
       "0                    0                       0                  0   \n",
       "1                    0                       0                  0   \n",
       "2                    0                       0                  1   \n",
       "3                    0                       0                  1   \n",
       "4                    0                       0                  1   \n",
       "\n",
       "   workclass-Self-emp-inc  workclass-Self-emp-not-inc  workclass-State-gov  \\\n",
       "0                       0                           0                    1   \n",
       "1                       0                           1                    0   \n",
       "2                       0                           0                    0   \n",
       "3                       0                           0                    0   \n",
       "4                       0                           0                    0   \n",
       "\n",
       "             ...              native-country-Portugal  \\\n",
       "0            ...                                    0   \n",
       "1            ...                                    0   \n",
       "2            ...                                    0   \n",
       "3            ...                                    0   \n",
       "4            ...                                    0   \n",
       "\n",
       "   native-country-Puerto-Rico  native-country-Scotland  native-country-South  \\\n",
       "0                           0                        0                     0   \n",
       "1                           0                        0                     0   \n",
       "2                           0                        0                     0   \n",
       "3                           0                        0                     0   \n",
       "4                           0                        0                     0   \n",
       "\n",
       "   native-country-Taiwan  native-country-Thailand  \\\n",
       "0                      0                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   native-country-Trinadad&Tobago  native-country-United-States  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             1   \n",
       "3                               0                             1   \n",
       "4                               0                             0   \n",
       "\n",
       "   native-country-Vietnam  native-country-Yugoslavia  \n",
       "0                       0                          0  \n",
       "1                       0                          0  \n",
       "2                       0                          0  \n",
       "3                       0                          0  \n",
       "4                       0                          0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not including education because it has strong correlation with education-num\n",
    "label_encode_col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "\n",
    "X_col = df.columns[:-1]\n",
    "print(X_col)\n",
    "X_cat_label_enc, y_encode = label_encode(df, X_col, label_encode_col)\n",
    "\n",
    "\n",
    "# print(X_label_enc.columns.tolist())\n",
    "\n",
    "X_cat_label_enc = X_cat_label_enc.drop(columns=['capital-gain', 'capital-loss'])\n",
    "\n",
    "X_cat_label_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that perform vertical quartile quantification and then horizontal binning\n",
    "Since several columns require the same procedure (age, capital-gain and capital-loss), will write functions here\n",
    "for calling <br>\n",
    "For capital-gain and capital-loss, because there are too many different horizontal values (different amount of capital-gain/capital-loss, thus, would just use a horizontal qcut and omit the vertical one. <br><br>\n",
    "Because most people have 0 capital-gain, most quartiles are concentrated close to 0 too.\n",
    "By setting duplicate drop, don't get to see a lot of different bins even though quartile cut is big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital-gain and capital-loss binning\n",
    "There are too many different values for capital-gain and capital-loss (and quite a few outliers).\n",
    "So similar to age feature engineering, I will use a vertical quartile quantification method to limit the horizontal ranges.\n",
    "\n",
    "\n",
    "The amount of money is again a continuous value, so might have to consider to similar things as age featuring\n",
    "where I do the horizontal binning based on levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_num_col(df, col_list, q_num, drop_zero=False):\n",
    "    # binning numerical columns with qcut. col should just be one column string. q_num is the number of bins to be made\n",
    "    # if drop_zero=True, set zero as one of the bin then drop it, then perform qcut with the rest\n",
    "    # print(df_process['capital-gain'])\n",
    "    # df_process['capital-gain'].value_counts() # Most people have 0 capital-gain (perhaps no investment?)\n",
    "    \n",
    "    for col in col_list:\n",
    "        binned = []\n",
    "    #     temp_df = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "        if drop_zero == True:\n",
    "            binned.extend([-0.01, 0.01])\n",
    "            temp_df = df[(df[col] < -0.01) | (df[col] > 0.01)][col]\n",
    "    #         print(temp_df)\n",
    "        else:\n",
    "            temp_df = df[col]\n",
    "\n",
    "        if col in df.columns:\n",
    "            ser, temp_binned = pd.qcut(temp_df, q=q_num, duplicates=\"drop\", retbins=True)\n",
    "            # With retbins=True, pd.qcut returns a tuple whose second element is the bins\n",
    "            # The first return element is a series while the second one is the break point\n",
    "            binned.extend(temp_binned)\n",
    "    #         print(binned)\n",
    "\n",
    "            # bin_cap_gain -= 0.01\n",
    "            # Need to do this because the cut is excluding the left hand side boundary value, which means 0 would not\n",
    "            # be include in (0 x]\n",
    "\n",
    "            binned_col = pd.cut(df[col], bins=binned, include_lowest=True)\n",
    "\n",
    "            binned_dummy = pd.get_dummies(binned_col,prefix= col + '_binned',prefix_sep='-')\n",
    "    #         df.drop(columns=[col], inplace=True)  \n",
    "            df = df.merge(binned_dummy, left_index=True, right_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-gain_binned-(-0.011, 0.01]</th>\n",
       "      <th>capital-gain_binned-(0.01, 114.0]</th>\n",
       "      <th>capital-gain_binned-(114.0, 3103.0]</th>\n",
       "      <th>capital-gain_binned-(3103.0, 5013.0]</th>\n",
       "      <th>capital-gain_binned-(5013.0, 7688.0]</th>\n",
       "      <th>capital-gain_binned-(7688.0, 15024.0]</th>\n",
       "      <th>capital-gain_binned-(15024.0, 99999.0]</th>\n",
       "      <th>capital-loss_binned-(-0.011, 0.01]</th>\n",
       "      <th>capital-loss_binned-(0.01, 155.0]</th>\n",
       "      <th>capital-loss_binned-(155.0, 1617.0]</th>\n",
       "      <th>capital-loss_binned-(1617.0, 1876.0]</th>\n",
       "      <th>capital-loss_binned-(1876.0, 1902.0]</th>\n",
       "      <th>capital-loss_binned-(1902.0, 2001.0]</th>\n",
       "      <th>capital-loss_binned-(2001.0, 4356.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   capital-gain_binned-(-0.011, 0.01]  capital-gain_binned-(0.01, 114.0]  \\\n",
       "0                                   0                                  0   \n",
       "1                                   1                                  0   \n",
       "2                                   1                                  0   \n",
       "3                                   1                                  0   \n",
       "4                                   1                                  0   \n",
       "\n",
       "   capital-gain_binned-(114.0, 3103.0]  capital-gain_binned-(3103.0, 5013.0]  \\\n",
       "0                                    1                                     0   \n",
       "1                                    0                                     0   \n",
       "2                                    0                                     0   \n",
       "3                                    0                                     0   \n",
       "4                                    0                                     0   \n",
       "\n",
       "   capital-gain_binned-(5013.0, 7688.0]  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   capital-gain_binned-(7688.0, 15024.0]  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   capital-gain_binned-(15024.0, 99999.0]  capital-loss_binned-(-0.011, 0.01]  \\\n",
       "0                                       0                                   1   \n",
       "1                                       0                                   1   \n",
       "2                                       0                                   1   \n",
       "3                                       0                                   1   \n",
       "4                                       0                                   1   \n",
       "\n",
       "   capital-loss_binned-(0.01, 155.0]  capital-loss_binned-(155.0, 1617.0]  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "\n",
       "   capital-loss_binned-(1617.0, 1876.0]  capital-loss_binned-(1876.0, 1902.0]  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "   capital-loss_binned-(1902.0, 2001.0]  capital-loss_binned-(2001.0, 4356.0]  \n",
       "0                                     0                                     0  \n",
       "1                                     0                                     0  \n",
       "2                                     0                                     0  \n",
       "3                                     0                                     0  \n",
       "4                                     0                                     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var_bin = bin_num_col(df, ['capital-gain', 'capital-loss'], 5, drop_zero=True)\n",
    "# df_var_bin = bin_num_col(df, 'capital-loss', 5, drop_zero=True)\n",
    "# df_process = bin_num_col(df_process, 'education-num', 5)\n",
    "\n",
    "X_var_bin = X_var_bin.drop(columns=['age', 'workclass', 'education', 'marital-status', 'occupation', \\\n",
    "                                        'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', \\\n",
    "                                        'income', 'hours-per-week', 'native-country'])\n",
    "\n",
    "X_var_bin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass-?</th>\n",
       "      <th>workclass-Federal-gov</th>\n",
       "      <th>workclass-Local-gov</th>\n",
       "      <th>workclass-Never-worked</th>\n",
       "      <th>workclass-Private</th>\n",
       "      <th>workclass-Self-emp-inc</th>\n",
       "      <th>workclass-Self-emp-not-inc</th>\n",
       "      <th>workclass-State-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>capital-gain_binned-(5013.0, 7688.0]</th>\n",
       "      <th>capital-gain_binned-(7688.0, 15024.0]</th>\n",
       "      <th>capital-gain_binned-(15024.0, 99999.0]</th>\n",
       "      <th>capital-loss_binned-(-0.011, 0.01]</th>\n",
       "      <th>capital-loss_binned-(0.01, 155.0]</th>\n",
       "      <th>capital-loss_binned-(155.0, 1617.0]</th>\n",
       "      <th>capital-loss_binned-(1617.0, 1876.0]</th>\n",
       "      <th>capital-loss_binned-(1876.0, 1902.0]</th>\n",
       "      <th>capital-loss_binned-(1902.0, 2001.0]</th>\n",
       "      <th>capital-loss_binned-(2001.0, 4356.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  hours-per-week  workclass-?  workclass-Federal-gov  \\\n",
       "0   39              40            0                      0   \n",
       "1   50              13            0                      0   \n",
       "2   38              40            0                      0   \n",
       "3   53              40            0                      0   \n",
       "4   28              40            0                      0   \n",
       "\n",
       "   workclass-Local-gov  workclass-Never-worked  workclass-Private  \\\n",
       "0                    0                       0                  0   \n",
       "1                    0                       0                  0   \n",
       "2                    0                       0                  1   \n",
       "3                    0                       0                  1   \n",
       "4                    0                       0                  1   \n",
       "\n",
       "   workclass-Self-emp-inc  workclass-Self-emp-not-inc  workclass-State-gov  \\\n",
       "0                       0                           0                    1   \n",
       "1                       0                           1                    0   \n",
       "2                       0                           0                    0   \n",
       "3                       0                           0                    0   \n",
       "4                       0                           0                    0   \n",
       "\n",
       "                   ...                   capital-gain_binned-(5013.0, 7688.0]  \\\n",
       "0                  ...                                                      0   \n",
       "1                  ...                                                      0   \n",
       "2                  ...                                                      0   \n",
       "3                  ...                                                      0   \n",
       "4                  ...                                                      0   \n",
       "\n",
       "   capital-gain_binned-(7688.0, 15024.0]  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "\n",
       "   capital-gain_binned-(15024.0, 99999.0]  capital-loss_binned-(-0.011, 0.01]  \\\n",
       "0                                       0                                   1   \n",
       "1                                       0                                   1   \n",
       "2                                       0                                   1   \n",
       "3                                       0                                   1   \n",
       "4                                       0                                   1   \n",
       "\n",
       "   capital-loss_binned-(0.01, 155.0]  capital-loss_binned-(155.0, 1617.0]  \\\n",
       "0                                  0                                    0   \n",
       "1                                  0                                    0   \n",
       "2                                  0                                    0   \n",
       "3                                  0                                    0   \n",
       "4                                  0                                    0   \n",
       "\n",
       "   capital-loss_binned-(1617.0, 1876.0]  capital-loss_binned-(1876.0, 1902.0]  \\\n",
       "0                                     0                                     0   \n",
       "1                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     0   \n",
       "4                                     0                                     0   \n",
       "\n",
       "   capital-loss_binned-(1902.0, 2001.0]  capital-loss_binned-(2001.0, 4356.0]  \n",
       "0                                     0                                     0  \n",
       "1                                     0                                     0  \n",
       "2                                     0                                     0  \n",
       "3                                     0                                     0  \n",
       "4                                     0                                     0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed = X_cat_label_enc.join(X_var_bin)\n",
    "\n",
    "X_processed.head()\n",
    "# This is the processed dataframe ready for ML model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree model building and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-34f0ee74c19e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_processed' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encode, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8108398587440504\n",
      "balanced accuracy score: 0.7394526346484915\n",
      "precision score: 0.6092843326885881\n",
      "average_precision score: 0.4626168581963265\n",
      "recall score: 0.6015276893698281\n",
      "F1-score: 0.6053811659192826\n",
      "confusion_matrix:\n",
      "[[4336  606]\n",
      " [ 626  945]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4942\n",
      "           1       0.61      0.60      0.61      1571\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.74      0.74      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "roc-score: 0.7394526346484916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21a89609cf8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a898a5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a85bd23c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "acc_score = metrics.accuracy_score(y_test, y_predict)\n",
    "print(\"accuracy score: \" + str(acc_score))\n",
    "\n",
    "ba_acc_score = metrics.balanced_accuracy_score(y_test, y_predict)\n",
    "print(\"balanced accuracy score: \" + str(ba_acc_score))\n",
    "\n",
    "prec_score = metrics.precision_score(y_test, y_predict)\n",
    "print(\"precision score: \" + str(prec_score))\n",
    "\n",
    "avg_prec_score = metrics.average_precision_score(y_test, y_predict)\n",
    "print(\"average_precision score: \" + str(avg_prec_score))\n",
    "\n",
    "recall_score = metrics.recall_score(y_test, y_predict)\n",
    "print(\"recall score: \" + str(recall_score))\n",
    "\n",
    "f1_score = metrics.f1_score(y_test, y_predict)\n",
    "print(\"F1-score: \" + str(f1_score))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_predict)\n",
    "print('confusion_matrix:')\n",
    "print(confusion_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "report = metrics.classification_report(y_test, y_predict)\n",
    "print('classification_report:')\n",
    "print(report)\n",
    "\n",
    "metrics.plot_confusion_matrix(clf, X_test, y_test, cmap='YlOrRd', normalize=None)\n",
    "\n",
    "\n",
    "## Getting AUROC value and plot ROC\n",
    "y_score = clf.predict_proba(X_test)\n",
    "print(y_score)\n",
    "y_test_lb = label_binarize(y_test, classes=[0, 1])\n",
    "print(y_test_lb)\n",
    "\n",
    "roc_auc_score = sklearn.metrics.roc_auc_score(y_test, y_predict)\n",
    "print('roc-score: ' + str(roc_auc_score))\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_lb, y_score[:, 1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.59007002 0.59007002 0.59134309 0.59898154 0.59961808\n",
      " 0.60089115 0.60152769 0.63717377 0.64035646 0.64162954 0.64162954\n",
      " 0.65117759 0.65117759 0.65117759 0.65117759 0.65372374 0.65372374\n",
      " 0.65563335 0.65626989 0.65881604 0.65945258 0.66072565 0.66072565\n",
      " 0.66072565 0.66136219 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ColumnTransformer takes a list of three-item tuples. The first value in the tuple is a name that labels it, the second is an instantiated estimator, and the third is a list of columns you want to apply the transformation to. The tuple will look like this:\n",
    "\n",
    "('name', SomeTransformer(parameters), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_ Bachelors']\n",
      "education     Bachelors\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "edu_train = df[['education']].copy()\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "edu_train_transformed = ohe.fit_transform(edu_train)\n",
    "feat_name = ohe.get_feature_names()\n",
    "# print(feat_name)\n",
    "print(feat_name[edu_train_transformed[0]==1])\n",
    "print(edu_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['MISSING'],\n",
       "       [' Bachelors'],\n",
       "       [' HS-grad'],\n",
       "       ...,\n",
       "       [' HS-grad'],\n",
       "       [' HS-grad'],\n",
       "       [' HS-grad']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_train.iloc[0, 0] = np.nan\n",
    "\n",
    "si = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "edu_train_imputed = si.fit_transform(edu_train)\n",
    "edu_train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 17)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu_train = df[['education']].copy()\n",
    "edu_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 17)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_step = ('si', SimpleImputer(strategy='constant',\n",
    "                fill_value='MISSING'))\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                handle_unknown='ignore'))\n",
    "steps = [si_step, ohe_step]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "edu_train = df[['education']].copy()\n",
    "edu_train.iloc[0, 0] = np.nan\n",
    "edu_transformed = pipe.fit_transform(edu_train)\n",
    "edu_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_si_step = ('si', SimpleImputer(strategy='constant',\n",
    "                   fill_value='MISSING'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                    handle_unknown='ignore'))\n",
    "\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "cat_cols = ['education', 'workclass']\n",
    "cat_transformers = [('cat', cat_pipe, cat_cols)]\n",
    "ct = ColumnTransformer(transformers=cat_transformers)\n",
    "\n",
    "X_cat_transformed = ct.fit_transform(df)\n",
    "X_cat_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_ 10th' 'x0_ 11th' 'x0_ 12th' 'x0_ 1st-4th' 'x0_ 5th-6th'\n",
      " 'x0_ 7th-8th' 'x0_ 9th' 'x0_ Assoc-acdm' 'x0_ Assoc-voc' 'x0_ Bachelors'\n",
      " 'x0_ Doctorate' 'x0_ HS-grad' 'x0_ Masters' 'x0_ Preschool'\n",
      " 'x0_ Prof-school' 'x0_ Some-college' 'x1_ ?' 'x1_ Federal-gov'\n",
      " 'x1_ Local-gov' 'x1_ Never-worked' 'x1_ Private' 'x1_ Self-emp-inc'\n",
      " 'x1_ Self-emp-not-inc' 'x1_ State-gov' 'x1_ Without-pay']\n"
     ]
    }
   ],
   "source": [
    "pl = ct.named_transformers_['cat']\n",
    "ohe = pl.named_steps['ohe']\n",
    "print(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 4)\n"
     ]
    }
   ],
   "source": [
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "num_transformers = [('num', num_pipe, num_col)]\n",
    "num_ct = ColumnTransformer(transformers=num_transformers)\n",
    "\n",
    "X_num_processed = num_ct.fit_transform(df)\n",
    "print(X_num_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining both transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_transformers = [('cat', cat_pipe, cat_cols), \\\n",
    "                         ('num', num_pipe, num_col)]\n",
    "comb_ct = ColumnTransformer(transformers=comb_transformers)\n",
    "\n",
    "X_comb_processed = comb_ct.fit_transform(df)\n",
    "X_comb_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('si',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='MISSING',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=N...\n",
       "      dtype=object))],\n",
       "                                   verbose=False)),\n",
       "                ('dt',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe = Pipeline([('transform', comb_ct), ('dt', tree.DecisionTreeClassifier())])\n",
    "\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encode, test_size=0.2, random_state=42)\n",
    "\n",
    "ml_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9115479115479116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80761554 0.81142506 0.80543612 0.80528256 0.80159705]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cr_score = cross_val_score(ml_pipe, X, y_encode, cv=kf)\n",
    "print(cr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transform',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('si',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value='MISSING',\n",
       "                                                                                                        missin...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'dt__criterion': ['gini', 'entropy'],\n",
       "                         'dt__max_depth': [2, 6, 10, 20],\n",
       "                         'dt__max_features': [None, 'log2'],\n",
       "                         'dt__min_samples_leaf': [1, 3],\n",
       "                         'dt__min_samples_split': [2, 6],\n",
       "                         'dt__splitter': ['best', 'random'],\n",
       "                         'transform__num__si__strategy': ['mean', 'median']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'transform__num__si__strategy': ['mean', 'median'],\n",
    "    'dt__splitter': ['best', 'random'],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [2, 6, 10, 20],\n",
    "    'dt__min_samples_split': [2, 6],\n",
    "    'dt__min_samples_leaf': [1, 3],\n",
    "    'dt__max_features': [None, 'log2'],\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(ml_pipe, param_grid, cv=kf)\n",
    "gs.fit(X, y_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch result can be converted into DataFrame to show the score of each parameter combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343724382646538\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': 10, 'dt__max_features': None, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 6, 'dt__splitter': 'best', 'transform__num__si__strategy': 'median'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_dt__criterion</th>\n",
       "      <th>param_dt__max_depth</th>\n",
       "      <th>param_dt__max_features</th>\n",
       "      <th>param_dt__min_samples_leaf</th>\n",
       "      <th>param_dt__min_samples_split</th>\n",
       "      <th>param_dt__splitter</th>\n",
       "      <th>param_transform__num__si__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.025142</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200253</td>\n",
       "      <td>0.038109</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.045072</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154462</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>0.772581</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>223</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>0.779945</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.763974</td>\n",
       "      <td>0.792537</td>\n",
       "      <td>0.034954</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.012022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162557</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.773594</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>220</td>\n",
       "      <td>0.777675</td>\n",
       "      <td>0.802058</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.760749</td>\n",
       "      <td>0.764896</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.015418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139842</td>\n",
       "      <td>0.029106</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.144205</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.131845</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.778908</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>207</td>\n",
       "      <td>0.770306</td>\n",
       "      <td>0.802058</td>\n",
       "      <td>0.764128</td>\n",
       "      <td>0.769502</td>\n",
       "      <td>0.788544</td>\n",
       "      <td>0.017285</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.014210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.146192</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.766285</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>236</td>\n",
       "      <td>0.776447</td>\n",
       "      <td>0.759367</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>0.768428</td>\n",
       "      <td>0.015645</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.006197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.133232</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145027</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.120073</td>\n",
       "      <td>0.025336</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>235</td>\n",
       "      <td>0.768924</td>\n",
       "      <td>0.768581</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.771345</td>\n",
       "      <td>0.762131</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.131444</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.762753</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>250</td>\n",
       "      <td>0.770459</td>\n",
       "      <td>0.758292</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.004173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.136421</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.152203</td>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.117695</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>0.768804</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>231</td>\n",
       "      <td>0.756641</td>\n",
       "      <td>0.761057</td>\n",
       "      <td>0.800215</td>\n",
       "      <td>0.763667</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.015884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.131640</td>\n",
       "      <td>0.025951</td>\n",
       "      <td>0.778692</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>209</td>\n",
       "      <td>0.798710</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>0.802979</td>\n",
       "      <td>0.763360</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.018239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.098320</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.780136</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>204</td>\n",
       "      <td>0.764625</td>\n",
       "      <td>0.803286</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.806204</td>\n",
       "      <td>0.766585</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.020228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.111888</td>\n",
       "      <td>0.026737</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>193</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>0.765971</td>\n",
       "      <td>0.765356</td>\n",
       "      <td>0.801290</td>\n",
       "      <td>0.817568</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.098327</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.771844</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>225</td>\n",
       "      <td>0.770306</td>\n",
       "      <td>0.765971</td>\n",
       "      <td>0.785012</td>\n",
       "      <td>0.770117</td>\n",
       "      <td>0.767813</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.006775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.116082</td>\n",
       "      <td>0.024524</td>\n",
       "      <td>0.762262</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>251</td>\n",
       "      <td>0.759251</td>\n",
       "      <td>0.763206</td>\n",
       "      <td>0.761978</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.102317</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.782624</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>198</td>\n",
       "      <td>0.769998</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.764435</td>\n",
       "      <td>0.798372</td>\n",
       "      <td>0.801904</td>\n",
       "      <td>0.011069</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.015018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.116904</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>0.786431</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>187</td>\n",
       "      <td>0.800706</td>\n",
       "      <td>0.758292</td>\n",
       "      <td>0.771038</td>\n",
       "      <td>0.798372</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.018303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.095548</td>\n",
       "      <td>0.026725</td>\n",
       "      <td>0.765056</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>241</td>\n",
       "      <td>0.768770</td>\n",
       "      <td>0.765817</td>\n",
       "      <td>0.765510</td>\n",
       "      <td>0.763974</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.002471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.113489</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.764872</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>244</td>\n",
       "      <td>0.760018</td>\n",
       "      <td>0.768581</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.768735</td>\n",
       "      <td>0.767045</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.102338</td>\n",
       "      <td>0.025117</td>\n",
       "      <td>0.764442</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>245</td>\n",
       "      <td>0.757101</td>\n",
       "      <td>0.764281</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.116478</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.766039</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>239</td>\n",
       "      <td>0.771841</td>\n",
       "      <td>0.765203</td>\n",
       "      <td>0.765510</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.767660</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.096338</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.765118</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>240</td>\n",
       "      <td>0.760940</td>\n",
       "      <td>0.768581</td>\n",
       "      <td>0.759982</td>\n",
       "      <td>0.771038</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.004263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.107918</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.771536</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>227</td>\n",
       "      <td>0.775986</td>\n",
       "      <td>0.758292</td>\n",
       "      <td>0.792998</td>\n",
       "      <td>0.769195</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.012393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.105130</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.767022</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>0.758292</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>0.772574</td>\n",
       "      <td>0.761210</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.006452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.782131</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'gini', 'dt__max_depth': 2, ...</td>\n",
       "      <td>200</td>\n",
       "      <td>0.801013</td>\n",
       "      <td>0.770885</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.013217</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.016890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.247132</td>\n",
       "      <td>0.027938</td>\n",
       "      <td>0.815362</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>105</td>\n",
       "      <td>0.822969</td>\n",
       "      <td>0.815878</td>\n",
       "      <td>0.810964</td>\n",
       "      <td>0.812961</td>\n",
       "      <td>0.814036</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.004123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.266493</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>0.818556</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.823737</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>0.827396</td>\n",
       "      <td>0.015241</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.005889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.325323</td>\n",
       "      <td>0.027541</td>\n",
       "      <td>0.826203</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.827576</td>\n",
       "      <td>0.828778</td>\n",
       "      <td>0.829085</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.825860</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.003435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.341120</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.826449</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.828957</td>\n",
       "      <td>0.828163</td>\n",
       "      <td>0.829392</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.254918</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.827462</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.824044</td>\n",
       "      <td>0.836456</td>\n",
       "      <td>0.820178</td>\n",
       "      <td>0.825246</td>\n",
       "      <td>0.831388</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.005761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.261890</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>46</td>\n",
       "      <td>0.824351</td>\n",
       "      <td>0.827856</td>\n",
       "      <td>0.816032</td>\n",
       "      <td>0.820946</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.322528</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.824606</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.824044</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>0.825246</td>\n",
       "      <td>0.820178</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.002665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.337269</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.824883</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.824505</td>\n",
       "      <td>0.828778</td>\n",
       "      <td>0.824939</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.002436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.235964</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.821351</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.821741</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.822942</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.258901</td>\n",
       "      <td>0.030126</td>\n",
       "      <td>0.817850</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>90</td>\n",
       "      <td>0.817596</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.815264</td>\n",
       "      <td>0.818335</td>\n",
       "      <td>0.818335</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.339879</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.825273</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.824171</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.346881</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>0.824637</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.824812</td>\n",
       "      <td>0.828317</td>\n",
       "      <td>0.825092</td>\n",
       "      <td>0.820485</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.250143</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>0.819564</td>\n",
       "      <td>0.818335</td>\n",
       "      <td>0.822174</td>\n",
       "      <td>0.823403</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.002505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.256313</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>0.817542</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.819438</td>\n",
       "      <td>0.823403</td>\n",
       "      <td>0.814650</td>\n",
       "      <td>0.812807</td>\n",
       "      <td>0.817414</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.003708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.148405</td>\n",
       "      <td>0.027331</td>\n",
       "      <td>0.820982</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.821588</td>\n",
       "      <td>0.831235</td>\n",
       "      <td>0.822789</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.814343</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.163368</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.821627</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.816060</td>\n",
       "      <td>0.827088</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.817414</td>\n",
       "      <td>0.829853</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.005683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.129260</td>\n",
       "      <td>0.026920</td>\n",
       "      <td>0.806763</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>120</td>\n",
       "      <td>0.810226</td>\n",
       "      <td>0.819564</td>\n",
       "      <td>0.809275</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>0.793151</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.008878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.141040</td>\n",
       "      <td>0.026321</td>\n",
       "      <td>0.804367</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.824505</td>\n",
       "      <td>0.807279</td>\n",
       "      <td>0.798679</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>0.796683</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.010946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.820644</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>60</td>\n",
       "      <td>0.822509</td>\n",
       "      <td>0.829392</td>\n",
       "      <td>0.810197</td>\n",
       "      <td>0.818643</td>\n",
       "      <td>0.822482</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.006270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.056354</td>\n",
       "      <td>0.819539</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>79</td>\n",
       "      <td>0.825426</td>\n",
       "      <td>0.818335</td>\n",
       "      <td>0.812807</td>\n",
       "      <td>0.815418</td>\n",
       "      <td>0.825706</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>0.040224</td>\n",
       "      <td>0.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.809865</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>113</td>\n",
       "      <td>0.809612</td>\n",
       "      <td>0.815571</td>\n",
       "      <td>0.805129</td>\n",
       "      <td>0.808814</td>\n",
       "      <td>0.810197</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.003355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.163364</td>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.807930</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>119</td>\n",
       "      <td>0.806848</td>\n",
       "      <td>0.806357</td>\n",
       "      <td>0.806050</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.813575</td>\n",
       "      <td>0.034753</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.151799</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>0.824330</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.827729</td>\n",
       "      <td>0.824785</td>\n",
       "      <td>0.817721</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.827088</td>\n",
       "      <td>0.017903</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.166346</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.832335</td>\n",
       "      <td>0.826474</td>\n",
       "      <td>0.815264</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.130254</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.800682</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>162</td>\n",
       "      <td>0.790880</td>\n",
       "      <td>0.815264</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.811271</td>\n",
       "      <td>0.791615</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.010419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.149204</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>0.805503</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>125</td>\n",
       "      <td>0.806080</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.796990</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.008318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.159183</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.825804</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.827883</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.820178</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.826935</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.163159</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.823071</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.823277</td>\n",
       "      <td>0.818643</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.004195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.121882</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.803262</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.804852</td>\n",
       "      <td>0.800215</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.802365</td>\n",
       "      <td>0.798065</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.004396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.140633</td>\n",
       "      <td>0.026725</td>\n",
       "      <td>0.801358</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>random</td>\n",
       "      <td>median</td>\n",
       "      <td>{'dt__criterion': 'entropy', 'dt__max_depth': ...</td>\n",
       "      <td>150</td>\n",
       "      <td>0.799632</td>\n",
       "      <td>0.794840</td>\n",
       "      <td>0.798219</td>\n",
       "      <td>0.806050</td>\n",
       "      <td>0.808047</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score param_dt__criterion  \\\n",
       "0         0.131446         0.025142         0.802617                gini   \n",
       "1         0.200253         0.038109         0.802617                gini   \n",
       "2         0.154462         0.029311         0.772581                gini   \n",
       "3         0.162557         0.028534         0.773594                gini   \n",
       "4         0.139842         0.029106         0.802617                gini   \n",
       "5         0.144205         0.026919         0.802617                gini   \n",
       "6         0.131845         0.025720         0.778908                gini   \n",
       "7         0.146192         0.027555         0.766285                gini   \n",
       "8         0.133232         0.027734         0.802617                gini   \n",
       "9         0.145027         0.024717         0.802617                gini   \n",
       "10        0.120073         0.025336         0.766715                gini   \n",
       "11        0.131444         0.024722         0.762753                gini   \n",
       "12        0.136421         0.024551         0.802617                gini   \n",
       "13        0.152203         0.026709         0.802617                gini   \n",
       "14        0.117695         0.024911         0.768804                gini   \n",
       "15        0.131640         0.025951         0.778692                gini   \n",
       "16        0.098320         0.025145         0.780136                gini   \n",
       "17        0.111888         0.026737         0.783607                gini   \n",
       "18        0.098327         0.024962         0.771844                gini   \n",
       "19        0.116082         0.024524         0.762262                gini   \n",
       "20        0.102317         0.025331         0.782624                gini   \n",
       "21        0.116904         0.024724         0.786431                gini   \n",
       "22        0.095548         0.026725         0.765056                gini   \n",
       "23        0.113489         0.026532         0.764872                gini   \n",
       "24        0.102338         0.025117         0.764442                gini   \n",
       "25        0.116478         0.027343         0.766039                gini   \n",
       "26        0.096338         0.027930         0.765118                gini   \n",
       "27        0.107918         0.026133         0.771536                gini   \n",
       "28        0.105130         0.028512         0.767022                gini   \n",
       "29        0.121875         0.025324         0.782131                gini   \n",
       "..             ...              ...              ...                 ...   \n",
       "226       0.247132         0.027938         0.815362             entropy   \n",
       "227       0.266493         0.027116         0.818556             entropy   \n",
       "228       0.325323         0.027541         0.826203             entropy   \n",
       "229       0.341120         0.027709         0.826449             entropy   \n",
       "230       0.254918         0.026716         0.827462             entropy   \n",
       "231       0.261890         0.031512         0.821719             entropy   \n",
       "232       0.322528         0.031525         0.824606             entropy   \n",
       "233       0.337269         0.026345         0.824883             entropy   \n",
       "234       0.235964         0.026945         0.821351             entropy   \n",
       "235       0.258901         0.030126         0.817850             entropy   \n",
       "236       0.339879         0.028336         0.824453             entropy   \n",
       "237       0.346881         0.028507         0.824637             entropy   \n",
       "238       0.250143         0.026525         0.819999             entropy   \n",
       "239       0.256313         0.029134         0.817542             entropy   \n",
       "240       0.148405         0.027331         0.820982             entropy   \n",
       "241       0.163368         0.025912         0.821627             entropy   \n",
       "242       0.129260         0.026920         0.806763             entropy   \n",
       "243       0.141040         0.026321         0.804367             entropy   \n",
       "244       0.150414         0.028905         0.820644             entropy   \n",
       "245       0.218216         0.056354         0.819539             entropy   \n",
       "246       0.152992         0.032313         0.809865             entropy   \n",
       "247       0.163364         0.029719         0.807930             entropy   \n",
       "248       0.151799         0.030333         0.824330             entropy   \n",
       "249       0.166346         0.029920         0.824821             entropy   \n",
       "250       0.130254         0.028924         0.800682             entropy   \n",
       "251       0.149204         0.028123         0.805503             entropy   \n",
       "252       0.159183         0.030308         0.825804             entropy   \n",
       "253       0.163159         0.027125         0.823071             entropy   \n",
       "254       0.121882         0.026922         0.803262             entropy   \n",
       "255       0.140633         0.026725         0.801358             entropy   \n",
       "\n",
       "    param_dt__max_depth param_dt__max_features param_dt__min_samples_leaf  \\\n",
       "0                     2                   None                          1   \n",
       "1                     2                   None                          1   \n",
       "2                     2                   None                          1   \n",
       "3                     2                   None                          1   \n",
       "4                     2                   None                          1   \n",
       "5                     2                   None                          1   \n",
       "6                     2                   None                          1   \n",
       "7                     2                   None                          1   \n",
       "8                     2                   None                          3   \n",
       "9                     2                   None                          3   \n",
       "10                    2                   None                          3   \n",
       "11                    2                   None                          3   \n",
       "12                    2                   None                          3   \n",
       "13                    2                   None                          3   \n",
       "14                    2                   None                          3   \n",
       "15                    2                   None                          3   \n",
       "16                    2                   log2                          1   \n",
       "17                    2                   log2                          1   \n",
       "18                    2                   log2                          1   \n",
       "19                    2                   log2                          1   \n",
       "20                    2                   log2                          1   \n",
       "21                    2                   log2                          1   \n",
       "22                    2                   log2                          1   \n",
       "23                    2                   log2                          1   \n",
       "24                    2                   log2                          3   \n",
       "25                    2                   log2                          3   \n",
       "26                    2                   log2                          3   \n",
       "27                    2                   log2                          3   \n",
       "28                    2                   log2                          3   \n",
       "29                    2                   log2                          3   \n",
       "..                  ...                    ...                        ...   \n",
       "226                  20                   None                          1   \n",
       "227                  20                   None                          1   \n",
       "228                  20                   None                          1   \n",
       "229                  20                   None                          1   \n",
       "230                  20                   None                          1   \n",
       "231                  20                   None                          1   \n",
       "232                  20                   None                          3   \n",
       "233                  20                   None                          3   \n",
       "234                  20                   None                          3   \n",
       "235                  20                   None                          3   \n",
       "236                  20                   None                          3   \n",
       "237                  20                   None                          3   \n",
       "238                  20                   None                          3   \n",
       "239                  20                   None                          3   \n",
       "240                  20                   log2                          1   \n",
       "241                  20                   log2                          1   \n",
       "242                  20                   log2                          1   \n",
       "243                  20                   log2                          1   \n",
       "244                  20                   log2                          1   \n",
       "245                  20                   log2                          1   \n",
       "246                  20                   log2                          1   \n",
       "247                  20                   log2                          1   \n",
       "248                  20                   log2                          3   \n",
       "249                  20                   log2                          3   \n",
       "250                  20                   log2                          3   \n",
       "251                  20                   log2                          3   \n",
       "252                  20                   log2                          3   \n",
       "253                  20                   log2                          3   \n",
       "254                  20                   log2                          3   \n",
       "255                  20                   log2                          3   \n",
       "\n",
       "    param_dt__min_samples_split param_dt__splitter  \\\n",
       "0                             2               best   \n",
       "1                             2               best   \n",
       "2                             2             random   \n",
       "3                             2             random   \n",
       "4                             6               best   \n",
       "5                             6               best   \n",
       "6                             6             random   \n",
       "7                             6             random   \n",
       "8                             2               best   \n",
       "9                             2               best   \n",
       "10                            2             random   \n",
       "11                            2             random   \n",
       "12                            6               best   \n",
       "13                            6               best   \n",
       "14                            6             random   \n",
       "15                            6             random   \n",
       "16                            2               best   \n",
       "17                            2               best   \n",
       "18                            2             random   \n",
       "19                            2             random   \n",
       "20                            6               best   \n",
       "21                            6               best   \n",
       "22                            6             random   \n",
       "23                            6             random   \n",
       "24                            2               best   \n",
       "25                            2               best   \n",
       "26                            2             random   \n",
       "27                            2             random   \n",
       "28                            6               best   \n",
       "29                            6               best   \n",
       "..                          ...                ...   \n",
       "226                           2             random   \n",
       "227                           2             random   \n",
       "228                           6               best   \n",
       "229                           6               best   \n",
       "230                           6             random   \n",
       "231                           6             random   \n",
       "232                           2               best   \n",
       "233                           2               best   \n",
       "234                           2             random   \n",
       "235                           2             random   \n",
       "236                           6               best   \n",
       "237                           6               best   \n",
       "238                           6             random   \n",
       "239                           6             random   \n",
       "240                           2               best   \n",
       "241                           2               best   \n",
       "242                           2             random   \n",
       "243                           2             random   \n",
       "244                           6               best   \n",
       "245                           6               best   \n",
       "246                           6             random   \n",
       "247                           6             random   \n",
       "248                           2               best   \n",
       "249                           2               best   \n",
       "250                           2             random   \n",
       "251                           2             random   \n",
       "252                           6               best   \n",
       "253                           6               best   \n",
       "254                           6             random   \n",
       "255                           6             random   \n",
       "\n",
       "    param_transform__num__si__strategy  \\\n",
       "0                                 mean   \n",
       "1                               median   \n",
       "2                                 mean   \n",
       "3                               median   \n",
       "4                                 mean   \n",
       "5                               median   \n",
       "6                                 mean   \n",
       "7                               median   \n",
       "8                                 mean   \n",
       "9                               median   \n",
       "10                                mean   \n",
       "11                              median   \n",
       "12                                mean   \n",
       "13                              median   \n",
       "14                                mean   \n",
       "15                              median   \n",
       "16                                mean   \n",
       "17                              median   \n",
       "18                                mean   \n",
       "19                              median   \n",
       "20                                mean   \n",
       "21                              median   \n",
       "22                                mean   \n",
       "23                              median   \n",
       "24                                mean   \n",
       "25                              median   \n",
       "26                                mean   \n",
       "27                              median   \n",
       "28                                mean   \n",
       "29                              median   \n",
       "..                                 ...   \n",
       "226                               mean   \n",
       "227                             median   \n",
       "228                               mean   \n",
       "229                             median   \n",
       "230                               mean   \n",
       "231                             median   \n",
       "232                               mean   \n",
       "233                             median   \n",
       "234                               mean   \n",
       "235                             median   \n",
       "236                               mean   \n",
       "237                             median   \n",
       "238                               mean   \n",
       "239                             median   \n",
       "240                               mean   \n",
       "241                             median   \n",
       "242                               mean   \n",
       "243                             median   \n",
       "244                               mean   \n",
       "245                             median   \n",
       "246                               mean   \n",
       "247                             median   \n",
       "248                               mean   \n",
       "249                             median   \n",
       "250                               mean   \n",
       "251                             median   \n",
       "252                               mean   \n",
       "253                             median   \n",
       "254                               mean   \n",
       "255                             median   \n",
       "\n",
       "                                                params  rank_test_score  \\\n",
       "0    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "1    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "2    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              223   \n",
       "3    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              220   \n",
       "4    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "5    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "6    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              207   \n",
       "7    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              236   \n",
       "8    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "9    {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "10   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              235   \n",
       "11   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              250   \n",
       "12   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "13   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              137   \n",
       "14   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              231   \n",
       "15   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              209   \n",
       "16   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              204   \n",
       "17   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              193   \n",
       "18   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              225   \n",
       "19   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              251   \n",
       "20   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              198   \n",
       "21   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              187   \n",
       "22   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              241   \n",
       "23   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              244   \n",
       "24   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              245   \n",
       "25   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              239   \n",
       "26   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              240   \n",
       "27   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              227   \n",
       "28   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              234   \n",
       "29   {'dt__criterion': 'gini', 'dt__max_depth': 2, ...              200   \n",
       "..                                                 ...              ...   \n",
       "226  {'dt__criterion': 'entropy', 'dt__max_depth': ...              105   \n",
       "227  {'dt__criterion': 'entropy', 'dt__max_depth': ...               86   \n",
       "228  {'dt__criterion': 'entropy', 'dt__max_depth': ...               27   \n",
       "229  {'dt__criterion': 'entropy', 'dt__max_depth': ...               26   \n",
       "230  {'dt__criterion': 'entropy', 'dt__max_depth': ...               25   \n",
       "231  {'dt__criterion': 'entropy', 'dt__max_depth': ...               46   \n",
       "232  {'dt__criterion': 'entropy', 'dt__max_depth': ...               35   \n",
       "233  {'dt__criterion': 'entropy', 'dt__max_depth': ...               31   \n",
       "234  {'dt__criterion': 'entropy', 'dt__max_depth': ...               51   \n",
       "235  {'dt__criterion': 'entropy', 'dt__max_depth': ...               90   \n",
       "236  {'dt__criterion': 'entropy', 'dt__max_depth': ...               37   \n",
       "237  {'dt__criterion': 'entropy', 'dt__max_depth': ...               34   \n",
       "238  {'dt__criterion': 'entropy', 'dt__max_depth': ...               76   \n",
       "239  {'dt__criterion': 'entropy', 'dt__max_depth': ...               93   \n",
       "240  {'dt__criterion': 'entropy', 'dt__max_depth': ...               54   \n",
       "241  {'dt__criterion': 'entropy', 'dt__max_depth': ...               49   \n",
       "242  {'dt__criterion': 'entropy', 'dt__max_depth': ...              120   \n",
       "243  {'dt__criterion': 'entropy', 'dt__max_depth': ...              130   \n",
       "244  {'dt__criterion': 'entropy', 'dt__max_depth': ...               60   \n",
       "245  {'dt__criterion': 'entropy', 'dt__max_depth': ...               79   \n",
       "246  {'dt__criterion': 'entropy', 'dt__max_depth': ...              113   \n",
       "247  {'dt__criterion': 'entropy', 'dt__max_depth': ...              119   \n",
       "248  {'dt__criterion': 'entropy', 'dt__max_depth': ...               38   \n",
       "249  {'dt__criterion': 'entropy', 'dt__max_depth': ...               32   \n",
       "250  {'dt__criterion': 'entropy', 'dt__max_depth': ...              162   \n",
       "251  {'dt__criterion': 'entropy', 'dt__max_depth': ...              125   \n",
       "252  {'dt__criterion': 'entropy', 'dt__max_depth': ...               28   \n",
       "253  {'dt__criterion': 'entropy', 'dt__max_depth': ...               40   \n",
       "254  {'dt__criterion': 'entropy', 'dt__max_depth': ...              135   \n",
       "255  {'dt__criterion': 'entropy', 'dt__max_depth': ...              150   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.801013           0.803286           0.803747   \n",
       "1             0.801013           0.803286           0.803747   \n",
       "2             0.766467           0.779945           0.759982   \n",
       "3             0.777675           0.802058           0.762592   \n",
       "4             0.801013           0.803286           0.803747   \n",
       "5             0.801013           0.803286           0.803747   \n",
       "6             0.770306           0.802058           0.764128   \n",
       "7             0.776447           0.759367           0.766892   \n",
       "8             0.801013           0.803286           0.803747   \n",
       "9             0.801013           0.803286           0.803747   \n",
       "10            0.768924           0.768581           0.762592   \n",
       "11            0.770459           0.758292           0.762592   \n",
       "12            0.801013           0.803286           0.803747   \n",
       "13            0.801013           0.803286           0.803747   \n",
       "14            0.756641           0.761057           0.800215   \n",
       "15            0.798710           0.767199           0.802979   \n",
       "16            0.764625           0.803286           0.759982   \n",
       "17            0.767849           0.765971           0.765356   \n",
       "18            0.770306           0.765971           0.785012   \n",
       "19            0.759251           0.763206           0.761978   \n",
       "20            0.769998           0.778409           0.764435   \n",
       "21            0.800706           0.758292           0.771038   \n",
       "22            0.768770           0.765817           0.765510   \n",
       "23            0.760018           0.768581           0.759982   \n",
       "24            0.757101           0.764281           0.767199   \n",
       "25            0.771841           0.765203           0.765510   \n",
       "26            0.760940           0.768581           0.759982   \n",
       "27            0.775986           0.758292           0.792998   \n",
       "28            0.767849           0.758292           0.775184   \n",
       "29            0.801013           0.770885           0.762592   \n",
       "..                 ...                ...                ...   \n",
       "226           0.822969           0.815878           0.810964   \n",
       "227           0.823737           0.814650           0.812500   \n",
       "228           0.827576           0.828778           0.829085   \n",
       "229           0.828957           0.828163           0.829392   \n",
       "230           0.824044           0.836456           0.820178   \n",
       "231           0.824351           0.827856           0.816032   \n",
       "232           0.824044           0.828471           0.825246   \n",
       "233           0.824505           0.828778           0.824939   \n",
       "234           0.821741           0.824478           0.818796   \n",
       "235           0.817596           0.819717           0.815264   \n",
       "236           0.825273           0.828471           0.824631   \n",
       "237           0.824812           0.828317           0.825092   \n",
       "238           0.816521           0.819564           0.818335   \n",
       "239           0.819438           0.823403           0.814650   \n",
       "240           0.821588           0.831235           0.822789   \n",
       "241           0.816060           0.827088           0.817721   \n",
       "242           0.810226           0.819564           0.809275   \n",
       "243           0.824505           0.807279           0.798679   \n",
       "244           0.822509           0.829392           0.810197   \n",
       "245           0.825426           0.818335           0.812807   \n",
       "246           0.809612           0.815571           0.805129   \n",
       "247           0.806848           0.806357           0.806050   \n",
       "248           0.827729           0.824785           0.817721   \n",
       "249           0.832335           0.826474           0.815264   \n",
       "250           0.790880           0.815264           0.794380   \n",
       "251           0.806080           0.819717           0.807432   \n",
       "252           0.827883           0.829699           0.820178   \n",
       "253           0.823277           0.818643           0.819410   \n",
       "254           0.804852           0.800215           0.810811   \n",
       "255           0.799632           0.794840           0.798219   \n",
       "\n",
       "     split3_test_score  split4_test_score  std_fit_time  std_score_time  \\\n",
       "0             0.801290           0.803747      0.007107        0.000746   \n",
       "1             0.801290           0.803747      0.045072        0.009810   \n",
       "2             0.763974           0.792537      0.034954        0.003382   \n",
       "3             0.760749           0.764896      0.030263        0.005475   \n",
       "4             0.801290           0.803747      0.012491        0.003300   \n",
       "5             0.801290           0.803747      0.005104        0.003798   \n",
       "6             0.769502           0.788544      0.017285        0.001817   \n",
       "7             0.760289           0.768428      0.015645        0.002293   \n",
       "8             0.801290           0.803747      0.014764        0.004663   \n",
       "9             0.801290           0.803747      0.007167        0.000740   \n",
       "10            0.771345           0.762131      0.007891        0.001017   \n",
       "11            0.759982           0.762439      0.010595        0.000761   \n",
       "12            0.801290           0.803747      0.009326        0.000483   \n",
       "13            0.801290           0.803747      0.016483        0.003068   \n",
       "14            0.763667           0.762439      0.005397        0.000901   \n",
       "15            0.763360           0.761210      0.004600        0.001883   \n",
       "16            0.806204           0.766585      0.003705        0.001465   \n",
       "17            0.801290           0.817568      0.006095        0.004128   \n",
       "18            0.770117           0.767813      0.007630        0.000901   \n",
       "19            0.759982           0.766892      0.004063        0.000465   \n",
       "20            0.798372           0.801904      0.011069        0.001737   \n",
       "21            0.798372           0.803747      0.006171        0.000750   \n",
       "22            0.763974           0.761210      0.003018        0.003757   \n",
       "23            0.768735           0.767045      0.006185        0.002576   \n",
       "24            0.772420           0.761210      0.010328        0.001152   \n",
       "25            0.759982           0.767660      0.008175        0.002878   \n",
       "26            0.771038           0.765049      0.004160        0.004525   \n",
       "27            0.769195           0.761210      0.004923        0.002623   \n",
       "28            0.772574           0.761210      0.009506        0.005388   \n",
       "29            0.772420           0.803747      0.013217        0.000497   \n",
       "..                 ...                ...           ...             ...   \n",
       "226           0.812961           0.814036      0.009774        0.002109   \n",
       "227           0.814496           0.827396      0.015241        0.001605   \n",
       "228           0.819717           0.825860      0.005400        0.002761   \n",
       "229           0.821100           0.824631      0.007369        0.003173   \n",
       "230           0.825246           0.831388      0.009621        0.000970   \n",
       "231           0.820946           0.819410      0.019614        0.004231   \n",
       "232           0.820178           0.825092      0.006342        0.005140   \n",
       "233           0.821100           0.825092      0.006266        0.001017   \n",
       "234           0.822942           0.818796      0.007553        0.001793   \n",
       "235           0.818335           0.818335      0.009826        0.006189   \n",
       "236           0.819717           0.824171      0.011649        0.002998   \n",
       "237           0.820485           0.824478      0.009531        0.003073   \n",
       "238           0.822174           0.823403      0.015367        0.000493   \n",
       "239           0.812807           0.817414      0.010605        0.004446   \n",
       "240           0.814957           0.814343      0.012008        0.001862   \n",
       "241           0.817414           0.829853      0.008981        0.000033   \n",
       "242           0.801597           0.793151      0.012187        0.002090   \n",
       "243           0.794687           0.796683      0.005433        0.001028   \n",
       "244           0.818643           0.822482      0.010859        0.005198   \n",
       "245           0.815418           0.825706      0.040490        0.040224   \n",
       "246           0.808814           0.810197      0.017520        0.004753   \n",
       "247           0.806818           0.813575      0.034753        0.002384   \n",
       "248           0.824324           0.827088      0.017903        0.005736   \n",
       "249           0.821560           0.828471      0.018738        0.003136   \n",
       "250           0.811271           0.791615      0.010504        0.003399   \n",
       "251           0.797297           0.796990      0.021803        0.002471   \n",
       "252           0.824324           0.826935      0.009203        0.003000   \n",
       "253           0.830467           0.823557      0.017711        0.001315   \n",
       "254           0.802365           0.798065      0.006048        0.003003   \n",
       "255           0.806050           0.808047      0.014690        0.001727   \n",
       "\n",
       "     std_test_score  \n",
       "0          0.001211  \n",
       "1          0.001211  \n",
       "2          0.012022  \n",
       "3          0.015418  \n",
       "4          0.001211  \n",
       "5          0.001211  \n",
       "6          0.014210  \n",
       "7          0.006197  \n",
       "8          0.001211  \n",
       "9          0.001211  \n",
       "10         0.003683  \n",
       "11         0.004173  \n",
       "12         0.001211  \n",
       "13         0.001211  \n",
       "14         0.015884  \n",
       "15         0.018239  \n",
       "16         0.020228  \n",
       "17         0.021718  \n",
       "18         0.006775  \n",
       "19         0.002708  \n",
       "20         0.015018  \n",
       "21         0.018303  \n",
       "22         0.002471  \n",
       "23         0.004022  \n",
       "24         0.005208  \n",
       "25         0.003846  \n",
       "26         0.004263  \n",
       "27         0.012393  \n",
       "28         0.006452  \n",
       "29         0.016890  \n",
       "..              ...  \n",
       "226        0.004123  \n",
       "227        0.005889  \n",
       "228        0.003435  \n",
       "229        0.003156  \n",
       "230        0.005761  \n",
       "231        0.004071  \n",
       "232        0.002665  \n",
       "233        0.002436  \n",
       "234        0.002259  \n",
       "235        0.001464  \n",
       "236        0.002805  \n",
       "237        0.002492  \n",
       "238        0.002505  \n",
       "239        0.003708  \n",
       "240        0.006150  \n",
       "241        0.005683  \n",
       "242        0.008878  \n",
       "243        0.010946  \n",
       "244        0.006270  \n",
       "245        0.005224  \n",
       "246        0.003355  \n",
       "247        0.002838  \n",
       "248        0.003551  \n",
       "249        0.005907  \n",
       "250        0.010419  \n",
       "251        0.008318  \n",
       "252        0.003305  \n",
       "253        0.004195  \n",
       "254        0.004396  \n",
       "255        0.004941  \n",
       "\n",
       "[256 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age feature engineering\n",
    "The ratio between people earning more than 50K and less than 50K changes with the age group.\n",
    "With that, binning would be more effective if we can set the boundary at which the ratios change a lot.\n",
    "\n",
    "1. In this example, all bins have more people earning less than 50K than people earning more than 50K. So the ratio would just be (Number of people earning less than 50K)/(Number of people earning more than 50K).\n",
    "2. Some of the ratios can be huge (at young age) compared to low ratios. To reduce the effect of big ratio and increase the effect of smaller ratio change, log transfomration would be applied\n",
    "3. Final step is to apply \"Bayesian blocks\", which is an adaptive method to find the optimal binning strategy\n",
    "\n",
    "For a set of histogram bins or blocks, each of an arbirary size, one can use a Bayesain likelihood framework to compute a fitness function which only depeds on two numbers: the width of each block, and the number of points in each block. The edges betwen these blocks (the change-points) can be varied, and the overall block configuration with the maximum fitness is quantitatively the est binning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_blocks(t):\n",
    "    \"\"\"Bayesian Blocks Implementation\n",
    "\n",
    "    By Jake Vanderplas.  License: BSD\n",
    "    Based on algorithm outlined in http://adsabs.harvard.edu/abs/2012arXiv1207.5578S\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, length N\n",
    "        data to be histogrammed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bins : ndarray\n",
    "        array containing the (N+1) bin edges\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is an incomplete implementation: it may fail for some\n",
    "    datasets.  Alternate fitness functions and prior forms can\n",
    "    be found in the paper listed above.\n",
    "    \"\"\"\n",
    "    # copy and sort the array\n",
    "    t = np.sort(t)\n",
    "    N = t.size\n",
    "\n",
    "    # create length-(N + 1) array of cell edges\n",
    "    edges = np.concatenate([t[:1],\n",
    "                            0.5 * (t[1:] + t[:-1]),\n",
    "                            t[-1:]])\n",
    "    block_length = t[-1] - edges\n",
    "\n",
    "    # arrays needed for the iteration\n",
    "    nn_vec = np.ones(N)\n",
    "    best = np.zeros(N, dtype=float)\n",
    "    last = np.zeros(N, dtype=int)\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # Start with first data cell; add one cell at each iteration\n",
    "    #-----------------------------------------------------------------\n",
    "    for K in range(N):\n",
    "        # Compute the width and count of the final bin for all possible\n",
    "        # locations of the K^th changepoint\n",
    "        width = block_length[:K + 1] - block_length[K + 1]\n",
    "        count_vec = np.cumsum(nn_vec[:K + 1][::-1])[::-1]\n",
    "\n",
    "        # evaluate fitness function for these possibilities\n",
    "        fit_vec = count_vec * (np.log(count_vec) - np.log(width))\n",
    "        fit_vec -= 4  # 4 comes from the prior on the number of changepoints\n",
    "        print(fit_vec)\n",
    "        fit_vec[1:] += best[:K]\n",
    "\n",
    "        # find the max of the fitness: this is the K^th changepoint\n",
    "        i_max = np.argmax(fit_vec)\n",
    "        last[K] = i_max\n",
    "        best[K] = fit_vec[i_max]\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # Recover changepoints by iteratively peeling off the last block\n",
    "    #-----------------------------------------------------------------\n",
    "    change_points =  np.zeros(N, dtype=int)\n",
    "    i_cp = N\n",
    "    ind = N\n",
    "    while True:\n",
    "        i_cp -= 1\n",
    "        change_points[i_cp] = ind\n",
    "        if ind == 0:\n",
    "            break\n",
    "        ind = last[ind - 1]\n",
    "    change_points = change_points[i_cp:]\n",
    "\n",
    "    return edges[change_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_age_ratio_diff = log_age_ratio.to_frame().T.diff(axis=1)\n",
    "\n",
    "log_age_ratio.plot.bar()\n",
    "log_age_ratio_diff.T.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hori_bound(s):\n",
    "# This function takes in either series or a list of time-series like values that have been quantified with vertical qcut\n",
    "# To reduce the number of discrete values in binning, a simple boundary values would be returned for horizontal qcut\n",
    "# Within each boundary, the vertical (y-axis) values would be the same\n",
    "# At the moment there is no smoothing method, bumpy vertical values within a long stretch of vertical values\n",
    "# would have its own boundary\n",
    "\n",
    "# The algorithm is simple too, whenever vertical value is the same, no boundary is set and move on to the next sample\n",
    "# If the vertical value is different, then a boundary is set and the new vertical value is set\n",
    "    bin_boundary = []\n",
    "    prev_yval = None\n",
    "    labels = []\n",
    "    \n",
    "#     curr_\n",
    "    \n",
    "    for row in s.iteritems():\n",
    "        if not prev_yval or not row[1] == prev_yval:\n",
    "            prev_yval = row[1]\n",
    "#             print(row.index)\n",
    "            bin_boundary.append(row[0])   \n",
    "    \n",
    "\n",
    "    return bin_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_qcut_val = pd.qcut(log_age_ratio, 5)\n",
    "print(vert_qcut_val.unique()[0].left)\n",
    "\n",
    "print(vert_qcut_val.unique())\n",
    "\n",
    "interval=[]\n",
    "mid_val = []\n",
    "labels = []\n",
    "\n",
    "for v in vert_qcut_val.unique():\n",
    "    interval.append(v.left)\n",
    "    interval.append(v.right)\n",
    "    mid_val.append((v.left + v.right)/2)\n",
    "    \n",
    "    \n",
    "vert_qcut_list = sorted(set(interval))\n",
    "mid_val_list = sorted(set(mid_val))\n",
    "\n",
    "print(mid_val_list)\n",
    "print(labels)\n",
    "\n",
    "bin_log_age_ratio = pd.cut(x=log_age_ratio, bins=vert_qcut_list, labels=mid_val_list)\n",
    "\n",
    "# bin_log_age_ratio.to_frame().T.plot.bar()\n",
    "# test.to_frame().plot.bar()\n",
    "bin_boundary = get_hori_bound(bin_log_age_ratio)\n",
    "\n",
    "df_process['age-binned'] = pd.cut(df_process['age'], bins=bin_boundary)\n",
    "\n",
    "age_binned_dummy = pd.get_dummies(df_process['age-binned'],prefix='age-binned',prefix_sep='-')\n",
    "\n",
    "# df_process.drop(columns=col, inplace=True)\n",
    "df_process = df_process.merge(age_binned_dummy, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "print(bin_boundary)\n",
    "# df_process[['age','age_binned']].head()\n",
    "df_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform automatic binning on continuous values\n",
    "\n",
    "# test = pd.qcut(df['age'].values, 5, \\\n",
    "#                labels=['young', 'prime-time', 'middle-age','retiring', 'senior']) # Categorical if given is array\n",
    "\n",
    "test = pd.qcut(df['age'], 10) # Categorical if given is array\n",
    "\n",
    "print(test.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
