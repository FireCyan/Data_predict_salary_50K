{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary investigation - Feature engineering and machine learning with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# sklearn.set_config(print_changed_only=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                int64\n",
      "workclass         object\n",
      "education         object\n",
      "marital-status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "gender            object\n",
      "capital-gain       int64\n",
      "capital-loss       int64\n",
      "hours-per-week     int64\n",
      "native-country    object\n",
      "dtype: object\n",
      "['age' 'capital-gain' 'capital-loss' 'hours-per-week']\n",
      "['workclass' 'education' 'marital-status' 'occupation' 'relationship'\n",
      " 'race' 'gender' 'native-country']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/adult.csv\", index_col=0)\n",
    "df['income'] = df['income'].str.replace(\" \", \"\")\n",
    "\n",
    "# remove the column education-num because it is similar to education\n",
    "df = df.drop(columns=['education-num'])\n",
    "df_X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "print(df_X.dtypes)\n",
    "\n",
    "kinds = np.array([dt.kind for dt in df_X.dtypes])\n",
    "# print(kinds)\n",
    "\n",
    "all_col = df_X.columns.values\n",
    "is_num = kinds != 'O'\n",
    "# print(is_num)\n",
    "num_col = all_col[is_num]\n",
    "print(num_col)\n",
    "\n",
    "cat_col = all_col[~is_num]\n",
    "print(cat_col)\n",
    "cat_col\n",
    "df_X.head()\n",
    "\n",
    "LEncoder = LabelEncoder()\n",
    "y_encode = LEncoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features:\n",
    "* Workclass (categorical)\n",
    "* education (categorical)\n",
    "* marital-status (categorical)\n",
    "* occupation (categorical)\n",
    "* relationship (categorical)\n",
    "* race (categorical)\n",
    "* gender (categorical)\n",
    "\n",
    "* native-country (categorical with engineering)\n",
    "\n",
    "\n",
    "* age (numerical values)\n",
    "* education-num (numerical values) (deleted)\n",
    "* hours-per-week (numerical values)\n",
    "* capital-gain (numerical values)\n",
    "* capital-loss (numerical values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ColumnTransformer takes a list of three-item tuples. The first value in the tuple is a name that labels it, the second is an instantiated estimator, and the third is a list of columns you want to apply the transformation to. The tuple will look like this:\n",
    "\n",
    "('name', SomeTransformer(parameters), columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_si_step = ('si', SimpleImputer(strategy='constant',\n",
    "                   fill_value='MISSING'))\n",
    "cat_ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                    handle_unknown='ignore'))\n",
    "\n",
    "cat_steps = [cat_si_step, cat_ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "# cat_transformers = [('cat', cat_pipe, cat_col)]\n",
    "# ct = ColumnTransformer(transformers=cat_transformers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numerical feature transformer\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "num_transformers = [('num', num_pipe, num_col)]\n",
    "num_ct = ColumnTransformer(transformers=num_transformers)\n",
    "\n",
    "# Combine both ColumnTransformer\n",
    "comb_transformers = [('cat', cat_pipe, cat_col), \\\n",
    "                     ('num', num_pipe, num_col)]\n",
    "comb_ct = ColumnTransformer(transformers=comb_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Columntransformer and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipe = Pipeline([('transform', comb_ct), ('dt', tree.DecisionTreeClassifier())])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_X, y_encode, test_size=0.2, random_state=42)\n",
    "# ml_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "cr_score = cross_val_score(ml_pipe, X, y_encode, cv=kf)\n",
    "print(cr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'transform__num__si__strategy': ['mean', 'median'],\n",
    "    'dt__splitter': ['best', 'random'],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [2, 6, 10, 20],\n",
    "    'dt__min_samples_split': [2, 6],\n",
    "    'dt__min_samples_leaf': [1, 3],\n",
    "    'dt__max_features': [None, 'log2'],\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(ml_pipe, param_grid, cv=kf)\n",
    "gs.fit(X, y_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch result can be converted into DataFrame to show the score of each parameter combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step demonstration of transform_step -> Pipeline -> ColumnTransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation step demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_ Bachelors']\n",
      "education     Bachelors\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['MISSING'],\n",
       "       [' Bachelors'],\n",
       "       [' HS-grad'],\n",
       "       ...,\n",
       "       [' HS-grad'],\n",
       "       [' HS-grad'],\n",
       "       [' HS-grad']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Demosntration of how two transform_steps (one-hot encoding and SimpleImputer) work on a column (chose 'education')\n",
    "\n",
    "edu_train = df[['education']].copy()\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "edu_train_transformed = ohe.fit_transform(edu_train)\n",
    "feat_name = ohe.get_feature_names()\n",
    "# print(feat_name)\n",
    "print(feat_name[edu_train_transformed[0]==1])\n",
    "print(edu_train.loc[0])\n",
    "\n",
    "# SimpleImputer\n",
    "edu_train.iloc[0, 0] = np.nan\n",
    "si = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "edu_train_imputed = si.fit_transform(edu_train)\n",
    "edu_train_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organise the SimpleImputer step into a pipeline-ready format (tuple with ('name', transform_step_func))\n",
    "si_step = ('si', SimpleImputer(strategy='constant',\n",
    "                fill_value='MISSING'))\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False,\n",
    "                handle_unknown='ignore'))\n",
    "\n",
    "# put the transformation_step into a list and initialise a pipeline with the tranformation step list\n",
    "steps = [si_step, ohe_step]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# Test the pipeline\n",
    "edu_train = df[['education']].copy()\n",
    "edu_train.iloc[0, 0] = np.nan\n",
    "edu_transformed = pipe.fit_transform(edu_train)\n",
    "edu_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTranformation demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_ 10th' 'x0_ 11th' 'x0_ 12th' 'x0_ 1st-4th' 'x0_ 5th-6th'\n",
      " 'x0_ 7th-8th' 'x0_ 9th' 'x0_ Assoc-acdm' 'x0_ Assoc-voc' 'x0_ Bachelors'\n",
      " 'x0_ Doctorate' 'x0_ HS-grad' 'x0_ Masters' 'x0_ Preschool'\n",
      " 'x0_ Prof-school' 'x0_ Some-college']\n"
     ]
    }
   ],
   "source": [
    "edu_transformers = [('edu_tf', pipe, ['education'])]\n",
    "edu_ct = ColumnTransformer(transformers=edu_transformers)\n",
    "\n",
    "X_edu_processed = edu_ct.fit_transform(df_X)\n",
    "X_edu_processed.shape\n",
    "pl = edu_ct.named_transformers_['edu_tf'] # Getting pipeline results back from the transformer\n",
    "ohe = pl.named_steps['ohe'] # Getting ohe result from the pipeline\n",
    "print(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining more than two pipelines into ColumnTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make another ColumnTransformer for numerical feature\n",
    "num_si_step = ('si', SimpleImputer(strategy='median'))\n",
    "num_ss_step = ('ss', StandardScaler())\n",
    "\n",
    "num_steps = [num_si_step, num_ss_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "num_transformers = [('num', num_pipe, num_col)]\n",
    "num_ct = ColumnTransformer(transformers=num_transformers)\n",
    "\n",
    "# Combine both ColumnTransformer\n",
    "comb_transformers = [('edu', pipe, ['education']), \\\n",
    "                         ('num', num_pipe, num_col)]\n",
    "comb_ct = ColumnTransformer(transformers=comb_transformers)\n",
    "\n",
    "X_comb_processed = comb_ct.fit_transform(df_X)\n",
    "X_comb_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Machine learning step using Pipeline again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('si',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='MISSING',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=N...\n",
       "      dtype=object))],\n",
       "                                   verbose=False)),\n",
       "                ('dt',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe = Pipeline([('transform', comb_ct), ('dt', tree.DecisionTreeClassifier())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, y_encode, test_size=0.2, random_state=42)\n",
    "ml_pipe.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
